{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d177e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = \"Data\"   # folder inside repo containing all runner CSVs\n",
    "\n",
    "# ------- HELPERS --------\n",
    "\n",
    "def seconds_to_mmss(value):\n",
    "    value = float(value)\n",
    "    minutes = int(value) // 60\n",
    "    seconds = int(value) % 60\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "\n",
    "def mph_to_pace(mph):\n",
    "    if pd.isna(mph) or mph <= 0:\n",
    "        return None\n",
    "    pace = 60 / mph\n",
    "    minutes = int(pace)\n",
    "    seconds = int(round((pace - minutes) * 60))\n",
    "    if seconds == 60:\n",
    "        minutes += 1\n",
    "        seconds = 0\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "\n",
    "# ------- READ & PROCESS ALL CSV FILES -------\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        \n",
    "        # Extract person name by removing extension (e.g., \"Alex.csv\" → \"Alex\")\n",
    "        person_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Read the file\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Add person column\n",
    "        df[\"Person\"] = person_name\n",
    "\n",
    "        # Keep only the needed columns\n",
    "        columns_to_keep = [\n",
    "            \"Activity Date\", \"Activity Type\", \"Elapsed Time\", \"Distance\", \"Moving Time\",\n",
    "            \"Max Speed\", \"Average Speed\", \"Elevation Gain\", \"Elevation Loss\",\n",
    "            \"Elevation Low\", \"Elevation High\", \"Max Grade\", \"Average Grade\",\n",
    "            \"Average Grade Adjusted Pace\", \"Person\"\n",
    "        ]\n",
    "        df = df[columns_to_keep]\n",
    "\n",
    "        # Filter to runs only\n",
    "        df = df[df[\"Activity Type\"] == \"Run\"]\n",
    "\n",
    "        # Format date\n",
    "        df[\"Activity Date\"] = pd.to_datetime(df[\"Activity Date\"], format=\"mixed\")\n",
    "        df[\"Activity Date\"] = df[\"Activity Date\"].dt.strftime(\"%-m/%-d/%y\")  # use %#m/%#d/%y on Windows\n",
    "\n",
    "        # Convert time columns\n",
    "        df[\"Elapsed Time\"] = df[\"Elapsed Time\"].apply(seconds_to_mmss)\n",
    "        df[\"Moving Time\"] = df[\"Moving Time\"].apply(seconds_to_mmss)\n",
    "\n",
    "        # Convert distance (km → miles)\n",
    "        df[\"Distance\"] = (df[\"Distance\"] * 0.621371).round(2)\n",
    "\n",
    "        # Convert speeds (m/s → mph)\n",
    "        df[\"Max Speed\"] = (df[\"Max Speed\"] * 2.23694).round(2)\n",
    "        df[\"Average Speed\"] = (df[\"Average Speed\"] * 2.23694).round(2)\n",
    "        df[\"Average Grade Adjusted Pace\"] = (df[\"Average Grade Adjusted Pace\"] * 2.23694).round(2)\n",
    "\n",
    "        # Convert elevation (m → ft)\n",
    "        meters_to_feet = 3.28084\n",
    "        elevation_cols = [\"Elevation Gain\", \"Elevation Loss\", \"Elevation Low\", \"Elevation High\"]\n",
    "        df[elevation_cols] = (df[elevation_cols] * meters_to_feet).round(1)\n",
    "\n",
    "        # Add new pace columns\n",
    "        df[\"Pace\"] = df[\"Average Speed\"].apply(mph_to_pace)\n",
    "        df[\"Grade Adjusted Pace\"] = df[\"Average Grade Adjusted Pace\"].apply(mph_to_pace)\n",
    "\n",
    "        # Store processed dataframe\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "# ------- MERGE ALL RUNNERS INTO ONE DF -------\n",
    "\n",
    "runs = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "runs = runs[\n",
    "    [\n",
    "        \"Activity Date\", \"Activity Type\", \"Elapsed Time\", \"Distance\", \"Pace\",\n",
    "        \"Elevation Loss\", \"Elevation Low\", \"Elevation High\", \"Max Grade\",\n",
    "        \"Average Grade\", \"Average Grade Adjusted Pace\", \"Grade Adjusted Pace\",\n",
    "        \"Person\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ba7f5",
   "metadata": {},
   "source": [
    "# 1. Exploratory Analysis, Data Collection, Pre-Preprocessing and Discussion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65df0b",
   "metadata": {},
   "source": [
    "## 1.1 Context\n",
    "**Where does your dataset come from? What is it for, how was it collected, etc.?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1217a929",
   "metadata": {},
   "source": [
    "Our dataset, stored in a DataFrame called `runs`, comes from our own exported GPS activity logs from Strava (a popular social media app to record workouts). We each downloaded our Strava data directly from Strava and merged the \"activity.cvs\" files together to create one comprehensive dataset with all of our data. We even got some of our friends who also use Strava regularly to send us their statistics as well. Each row corresponds to a single activity with summary statistics such as:\n",
    "\n",
    "- `Activity Date`, `Activity Type`\n",
    "- `Elapsed Time`, `Moving Time`\n",
    "- `Distance`\n",
    "- `Pace`\n",
    "- `Elevation Gain`, `Elevation Loss`, `Elevation Low`, `Elevation High`\n",
    "- `Max Grade`, `Average Grade`\n",
    "- `Person`\n",
    "\n",
    "We focus on **running activities** where `Activity Type` indicates a run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff9cd18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity Date</th>\n",
       "      <th>Activity Type</th>\n",
       "      <th>Elapsed Time</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Pace</th>\n",
       "      <th>Moving Time</th>\n",
       "      <th>Max Speed</th>\n",
       "      <th>Average Speed</th>\n",
       "      <th>Elevation Gain</th>\n",
       "      <th>Elevation Loss</th>\n",
       "      <th>Elevation Low</th>\n",
       "      <th>Elevation High</th>\n",
       "      <th>Max Grade</th>\n",
       "      <th>Average Grade</th>\n",
       "      <th>Average Grade Adjusted Pace</th>\n",
       "      <th>Grade Adjusted Pace</th>\n",
       "      <th>Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>6/8/25</td>\n",
       "      <td>Run</td>\n",
       "      <td>100:28</td>\n",
       "      <td>3.46</td>\n",
       "      <td>9:53</td>\n",
       "      <td>34:14</td>\n",
       "      <td>9.26</td>\n",
       "      <td>6.07</td>\n",
       "      <td>235.9</td>\n",
       "      <td>236.2</td>\n",
       "      <td>315.6</td>\n",
       "      <td>444.6</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6.11</td>\n",
       "      <td>9:49</td>\n",
       "      <td>Zubin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>10/17/25</td>\n",
       "      <td>Run</td>\n",
       "      <td>34:06</td>\n",
       "      <td>4.58</td>\n",
       "      <td>7:26</td>\n",
       "      <td>34:05</td>\n",
       "      <td>10.78</td>\n",
       "      <td>8.07</td>\n",
       "      <td>221.8</td>\n",
       "      <td>221.8</td>\n",
       "      <td>229.0</td>\n",
       "      <td>367.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.19</td>\n",
       "      <td>7:20</td>\n",
       "      <td>Zubin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>11/11/25</td>\n",
       "      <td>Run</td>\n",
       "      <td>42:25</td>\n",
       "      <td>2.32</td>\n",
       "      <td>9:42</td>\n",
       "      <td>22:31</td>\n",
       "      <td>10.96</td>\n",
       "      <td>6.19</td>\n",
       "      <td>203.4</td>\n",
       "      <td>183.7</td>\n",
       "      <td>184.4</td>\n",
       "      <td>404.5</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>9:13</td>\n",
       "      <td>Karina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>11/21/24</td>\n",
       "      <td>Run</td>\n",
       "      <td>10:16</td>\n",
       "      <td>1.01</td>\n",
       "      <td>9:58</td>\n",
       "      <td>10:03</td>\n",
       "      <td>9.89</td>\n",
       "      <td>6.02</td>\n",
       "      <td>43.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>407.8</td>\n",
       "      <td>442.3</td>\n",
       "      <td>30.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.08</td>\n",
       "      <td>9:52</td>\n",
       "      <td>Audrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>3/27/25</td>\n",
       "      <td>Run</td>\n",
       "      <td>47:22</td>\n",
       "      <td>6.23</td>\n",
       "      <td>7:36</td>\n",
       "      <td>47:22</td>\n",
       "      <td>10.60</td>\n",
       "      <td>7.89</td>\n",
       "      <td>119.1</td>\n",
       "      <td>118.8</td>\n",
       "      <td>138.8</td>\n",
       "      <td>217.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7:34</td>\n",
       "      <td>Alex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Activity Date Activity Type Elapsed Time  Distance  Pace Moving Time  \\\n",
       "378        6/8/25           Run       100:28      3.46  9:53       34:14   \n",
       "415      10/17/25           Run        34:06      4.58  7:26       34:05   \n",
       "26       11/11/25           Run        42:25      2.32  9:42       22:31   \n",
       "273      11/21/24           Run        10:16      1.01  9:58       10:03   \n",
       "180       3/27/25           Run        47:22      6.23  7:36       47:22   \n",
       "\n",
       "     Max Speed  Average Speed  Elevation Gain  Elevation Loss  Elevation Low  \\\n",
       "378       9.26           6.07           235.9           236.2          315.6   \n",
       "415      10.78           8.07           221.8           221.8          229.0   \n",
       "26       10.96           6.19           203.4           183.7          184.4   \n",
       "273       9.89           6.02            43.0            21.7          407.8   \n",
       "180      10.60           7.89           119.1           118.8          138.8   \n",
       "\n",
       "     Elevation High  Max Grade  Average Grade  Average Grade Adjusted Pace  \\\n",
       "378           444.6       47.7            0.1                         6.11   \n",
       "415           367.1       11.9            0.0                         8.19   \n",
       "26            404.5       35.3            0.0                         6.51   \n",
       "273           442.3       30.3            0.4                         6.08   \n",
       "180           217.2       10.2            0.0                         7.93   \n",
       "\n",
       "    Grade Adjusted Pace  Person  \n",
       "378                9:49   Zubin  \n",
       "415                7:20   Zubin  \n",
       "26                 9:13  Karina  \n",
       "273                9:52  Audrey  \n",
       "180                7:34    Alex  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8040b403",
   "metadata": {},
   "source": [
    "## 1.2 Discussion\n",
    "**Report how you processed the data (or how it was already processed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053e0b22",
   "metadata": {},
   "source": [
    "Key preprocessing steps:\n",
    "\n",
    "- Add person column \n",
    "- Keep only relevant columns (activity, time, elevation, grade, person)\n",
    "- Format columns to not be in imperial system (time column, mph column, distance, speed) \n",
    "- Filter to **running activities** only\n",
    "- Merge all runners into one dataframe \n",
    "- Split into train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f2a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_folder = \"Data\"   # folder inside repo containing all runner CSVs\n",
    "\n",
    "# ------- HELPERS --------\n",
    "\n",
    "def seconds_to_mmss(value):\n",
    "    value = float(value)\n",
    "    minutes = int(value) // 60\n",
    "    seconds = int(value) % 60\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "\n",
    "def mph_to_pace(mph):\n",
    "    if pd.isna(mph) or mph <= 0:\n",
    "        return None\n",
    "    pace = 60 / mph\n",
    "    minutes = int(pace)\n",
    "    seconds = int(round((pace - minutes) * 60))\n",
    "    if seconds == 60:\n",
    "        minutes += 1\n",
    "        seconds = 0\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "\n",
    "# ------- READ & PROCESS ALL CSV FILES -------\n",
    "\n",
    "all_dataframes = []\n",
    "\n",
    "for filename in os.listdir(data_folder):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        \n",
    "        # Extract person name by removing extension (e.g., \"Alex.csv\" → \"Alex\")\n",
    "        person_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        # Read the file\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Add person column\n",
    "        df[\"Person\"] = person_name\n",
    "\n",
    "        # Keep only the needed columns\n",
    "        columns_to_keep = [\n",
    "            \"Activity Date\", \"Activity Type\", \"Elapsed Time\", \"Distance\", \"Moving Time\",\n",
    "            \"Max Speed\", \"Average Speed\", \"Elevation Gain\", \"Elevation Loss\",\n",
    "            \"Elevation Low\", \"Elevation High\", \"Max Grade\", \"Average Grade\",\n",
    "            \"Average Grade Adjusted Pace\", \"Person\"\n",
    "        ]\n",
    "        df = df[columns_to_keep]\n",
    "\n",
    "        # Filter to runs only\n",
    "        df = df[df[\"Activity Type\"] == \"Run\"]\n",
    "\n",
    "        # Format date\n",
    "        df[\"Activity Date\"] = pd.to_datetime(df[\"Activity Date\"], format=\"mixed\")\n",
    "        df[\"Activity Date\"] = df[\"Activity Date\"].dt.strftime(\"%-m/%-d/%y\")  # use %#m/%#d/%y on Windows\n",
    "\n",
    "        # Convert time columns\n",
    "        df[\"Elapsed Time\"] = df[\"Elapsed Time\"].apply(seconds_to_mmss)\n",
    "        df[\"Moving Time\"] = df[\"Moving Time\"].apply(seconds_to_mmss)\n",
    "\n",
    "        # Convert distance (km → miles)\n",
    "        df[\"Distance\"] = (df[\"Distance\"] * 0.621371).round(2)\n",
    "\n",
    "        # Convert speeds (m/s → mph)\n",
    "        df[\"Max Speed\"] = (df[\"Max Speed\"] * 2.23694).round(2)\n",
    "        df[\"Average Speed\"] = (df[\"Average Speed\"] * 2.23694).round(2)\n",
    "        df[\"Average Grade Adjusted Pace\"] = (df[\"Average Grade Adjusted Pace\"] * 2.23694).round(2)\n",
    "\n",
    "        # Convert elevation (m → ft)\n",
    "        meters_to_feet = 3.28084\n",
    "        elevation_cols = [\"Elevation Gain\", \"Elevation Loss\", \"Elevation Low\", \"Elevation High\"]\n",
    "        df[elevation_cols] = (df[elevation_cols] * meters_to_feet).round(1)\n",
    "\n",
    "        # Add new pace columns\n",
    "        df[\"Pace\"] = df[\"Average Speed\"].apply(mph_to_pace)\n",
    "        df[\"Grade Adjusted Pace\"] = df[\"Average Grade Adjusted Pace\"].apply(mph_to_pace)\n",
    "\n",
    "        # Store processed dataframe\n",
    "        all_dataframes.append(df)\n",
    "\n",
    "# ------- MERGE ALL RUNNERS INTO ONE DF -------\n",
    "\n",
    "runs = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "runs = runs[\n",
    "    [\n",
    "        \"Activity Date\", \"Activity Type\", \"Elapsed Time\", \"Distance\", \"Pace\",\n",
    "        \"Moving Time\", \"Max Speed\", \"Average Speed\", \"Elevation Gain\",\n",
    "        \"Elevation Loss\", \"Elevation Low\", \"Elevation High\", \"Max Grade\",\n",
    "        \"Average Grade\", \"Average Grade Adjusted Pace\", \"Grade Adjusted Pace\",\n",
    "        \"Person\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e224f56",
   "metadata": {},
   "source": [
    "## 1.3 Code \n",
    "**Support your analysis with tables, plots, statistics, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acfdcb4",
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# Set style for better-looking plots\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.figsize'] = (12, 6)\n\n# --- BASIC DATASET STATISTICS ---\nprint(\"=\" * 60)\nprint(\"DATASET OVERVIEW\")\nprint(\"=\" * 60)\nprint(f\"Total number of runs: {len(runs)}\")\nprint(f\"Number of unique runners: {runs['Person'].nunique()}\")\nprint(f\"Date range: {runs['Activity Date'].min()} to {runs['Activity Date'].max()}\")\nprint()\n\n# --- RUNS PER PERSON ---\nprint(\"=\" * 60)\nprint(\"RUNS PER PERSON\")\nprint(\"=\" * 60)\nruns_per_person = runs.groupby('Person').size().sort_values(ascending=False)\nprint(runs_per_person)\nprint()\n\n# --- VISUALIZE RUNS PER PERSON ---\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nruns_per_person.plot(kind='bar', ax=ax, color='steelblue')\nax.set_title('Number of Runs per Person', fontsize=14, fontweight='bold')\nax.set_xlabel('Person', fontsize=12)\nax.set_ylabel('Number of Runs', fontsize=12)\nax.tick_params(axis='x', rotation=45)\nplt.tight_layout()\nplt.show()\n\n# --- CONVERT PACE TO NUMERIC FOR ANALYSIS ---\ndef pace_str_to_float(p):\n    if pd.isna(p):\n        return np.nan\n    if isinstance(p, str) and \":\" in p:\n        m, s = p.split(\":\")\n        return float(m) + float(s)/60\n    return float(p)\n\nruns['Pace_numeric'] = runs['Pace'].apply(pace_str_to_float)\nruns['Grade Adjusted Pace_numeric'] = runs['Grade Adjusted Pace'].apply(pace_str_to_float)\n\n# --- REMOVE EXTREME OUTLIERS (pace > 30 min/mile is unrealistic for running) ---\nprint(\"=\" * 60)\nprint(\"OUTLIER REMOVAL\")\nprint(\"=\" * 60)\nprint(f\"Runs before outlier removal: {len(runs)}\")\nruns_clean = runs[runs['Pace_numeric'] <= 30].copy()\nprint(f\"Runs after removing pace outliers (pace > 30 min/mile): {len(runs_clean)}\")\nprint(f\"Removed {len(runs) - len(runs_clean)} outlier runs\")\nprint()\n\n# Use cleaned data for all subsequent analysis\nruns = runs_clean\n\n# --- SUMMARY STATISTICS BY PERSON ---\nprint(\"=\" * 60)\nprint(\"SUMMARY STATISTICS BY PERSON\")\nprint(\"=\" * 60)\nsummary_stats = runs.groupby('Person').agg({\n    'Distance': ['mean', 'std', 'min', 'max'],\n    'Pace_numeric': ['mean', 'std', 'min', 'max'],\n    'Elevation Gain': ['mean', 'std'],\n    'Average Grade': ['mean', 'std']\n}).round(2)\nprint(summary_stats)\nprint()\n\n# --- DISTRIBUTION OF DISTANCES ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Overall distance distribution\naxes[0].hist(runs['Distance'], bins=30, color='skyblue', edgecolor='black', alpha=0.7)\naxes[0].set_title('Distribution of Run Distances', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Distance (miles)', fontsize=12)\naxes[0].set_ylabel('Frequency', fontsize=12)\naxes[0].axvline(runs['Distance'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {runs[\"Distance\"].mean():.2f}')\naxes[0].legend()\n\n# Distance distribution by person\nfor person in runs['Person'].unique():\n    person_data = runs[runs['Person'] == person]['Distance']\n    axes[1].hist(person_data, bins=20, alpha=0.5, label=person, edgecolor='black')\naxes[1].set_title('Distance Distribution by Person', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Distance (miles)', fontsize=12)\naxes[1].set_ylabel('Frequency', fontsize=12)\naxes[1].legend()\n\nplt.tight_layout()\nplt.show()\n\n# --- DISTRIBUTION OF PACE ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Overall pace distribution\naxes[0].hist(runs['Pace_numeric'].dropna(), bins=30, color='lightcoral', edgecolor='black', alpha=0.7)\naxes[0].set_title('Distribution of Pace (Outliers Removed)', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Pace (min/mile)', fontsize=12)\naxes[0].set_ylabel('Frequency', fontsize=12)\naxes[0].axvline(runs['Pace_numeric'].mean(), color='darkred', linestyle='--', linewidth=2, label=f'Mean: {runs[\"Pace_numeric\"].mean():.2f}')\naxes[0].legend()\n\n# Pace distribution by person (boxplot)\nruns.boxplot(column='Pace_numeric', by='Person', ax=axes[1], patch_artist=True)\naxes[1].set_title('Pace Distribution by Person (Outliers Removed)', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Person', fontsize=12)\naxes[1].set_ylabel('Pace (min/mile)', fontsize=12)\nplt.suptitle('')  # Remove the automatic title from boxplot\n\nplt.tight_layout()\nplt.show()\n\n# --- ELEVATION GAIN ANALYSIS ---\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Overall elevation gain distribution\naxes[0].hist(runs['Elevation Gain'].dropna(), bins=30, color='lightgreen', edgecolor='black', alpha=0.7)\naxes[0].set_title('Distribution of Elevation Gain', fontsize=14, fontweight='bold')\naxes[0].set_xlabel('Elevation Gain (ft)', fontsize=12)\naxes[0].set_ylabel('Frequency', fontsize=12)\naxes[0].axvline(runs['Elevation Gain'].mean(), color='darkgreen', linestyle='--', linewidth=2, label=f'Mean: {runs[\"Elevation Gain\"].mean():.2f}')\naxes[0].legend()\n\n# Elevation gain by person\nelevation_by_person = runs.groupby('Person')['Elevation Gain'].mean().sort_values()\nelevation_by_person.plot(kind='barh', ax=axes[1], color='seagreen')\naxes[1].set_title('Average Elevation Gain by Person', fontsize=14, fontweight='bold')\naxes[1].set_xlabel('Average Elevation Gain (ft)', fontsize=12)\naxes[1].set_ylabel('Person', fontsize=12)\n\nplt.tight_layout()\nplt.show()\n\n# --- CORRELATION ANALYSIS ---\nprint(\"=\" * 60)\nprint(\"CORRELATION ANALYSIS\")\nprint(\"=\" * 60)\nnumeric_cols = ['Distance', 'Pace_numeric', 'Elevation Gain', 'Elevation Loss',\n                'Elevation Low', 'Elevation High', 'Max Grade', 'Average Grade']\ncorrelation_matrix = runs[numeric_cols].corr()\nprint(correlation_matrix.round(2))\nprint()\n\n# Visualize correlation matrix\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\nplt.title('Correlation Matrix of Running Features', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\n# --- PACE vs DISTANCE SCATTER ---\nplt.figure(figsize=(10, 6))\nfor person in runs['Person'].unique():\n    person_data = runs[runs['Person'] == person]\n    plt.scatter(person_data['Distance'], person_data['Pace_numeric'],\n                alpha=0.6, label=person, s=50)\nplt.xlabel('Distance (miles)', fontsize=12)\nplt.ylabel('Pace (min/mile)', fontsize=12)\nplt.title('Pace vs Distance by Person', fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# --- TEMPORAL TRENDS ---\nruns['Activity Date'] = pd.to_datetime(runs['Activity Date'])\nruns_sorted = runs.sort_values('Activity Date')\n\nplt.figure(figsize=(14, 6))\nfor person in runs['Person'].unique():\n    person_data = runs_sorted[runs_sorted['Person'] == person]\n    plt.plot(person_data['Activity Date'], person_data['Distance'],\n             marker='o', alpha=0.7, label=person, markersize=4)\nplt.xlabel('Date', fontsize=12)\nplt.ylabel('Distance (miles)', fontsize=12)\nplt.title('Running Distance Over Time by Person', fontsize=14, fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\n# --- KEY INSIGHTS ---\nprint(\"=\" * 60)\nprint(\"KEY INSIGHTS\")\nprint(\"=\" * 60)\nprint(f\"• Average run distance: {runs['Distance'].mean():.2f} miles\")\nprint(f\"• Average pace: {runs['Pace_numeric'].mean():.2f} min/mile\")\nprint(f\"• Average elevation gain: {runs['Elevation Gain'].mean():.2f} feet\")\nprint(f\"• Most active runner: {runs_per_person.idxmax()} with {runs_per_person.max()} runs\")\nprint(f\"• Fastest average pace: {runs.groupby('Person')['Pace_numeric'].mean().idxmin()}\")\nprint(f\"• Longest average distance: {runs.groupby('Person')['Distance'].mean().idxmax()}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "id": "3fddedf9",
   "metadata": {},
   "source": [
    "# 2. Predictive Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6da95",
   "metadata": {},
   "source": [
    "## 2.1 Task Definition\n",
    "**Identify the predictive task you will study**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace2a4c2",
   "metadata": {},
   "source": [
    "We study a **supervised regression** task focused on modeling short-term training dynamics in runners.\n",
    "\n",
    "> **Given a runner’s recent training history, predict the pace and distance of their *next run*.**\n",
    "\n",
    "Each data point is constructed using a sliding time window over past runs for an individual runner, and the target corresponds to the immediately following run. This allows us to model **temporal trends, fitness adaptation, and training consistency**.\n",
    "\n",
    "### Inputs (Features)\n",
    "\n",
    "For each runner and each prediction point, we use summary **trend-based features** computed from the previous 5 runs:\n",
    "\n",
    "- **Pace history**\n",
    "  - Mean pace over last 5 runs  \n",
    "  - Standard deviation of pace  \n",
    "  - Most recent pace  \n",
    "  - Linear slope of pace over last 5 runs (trend)\n",
    "\n",
    "- **Distance history**\n",
    "  - Mean distance over last 5 runs  \n",
    "  - Standard deviation of distance  \n",
    "  - Most recent distance  \n",
    "  - Linear slope of distance over last 5 runs (trend)\n",
    "\n",
    "- **Training load & terrain**\n",
    "  - Mean elevation gain over last 5 runs  \n",
    "  - Mean grade over last 5 runs  \n",
    "\n",
    "- **Recovery**\n",
    "  - Days since last run  \n",
    "\n",
    "- **Identity**\n",
    "  - Runner identity (`Person`, one-hot encoded)\n",
    "\n",
    "These features jointly encode **current fitness level, training direction, consistency, and recovery behavior**.\n",
    "\n",
    "### Outputs (Targets)\n",
    "\n",
    "We perform **two regression tasks**:\n",
    "\n",
    "- `next_run_pace`: numeric pace of the next run (minutes per mile)\n",
    "- `next_run_distance`: numeric distance of the next run (miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7f5444",
   "metadata": {},
   "source": [
    "## 2.2 Evaluation Strategy\n",
    "**Describe how you will evaluate your model at this predictive task**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8856865",
   "metadata": {},
   "source": [
    "We evaluate our models using a **train/validation/test split**:\n",
    "\n",
    "- Split the dataset into:\n",
    "  - **Training set**: fit the model and (via cross-validation) tune hyperparameters.\n",
    "  - **Test set**: held-out data for final performance reporting.\n",
    "\n",
    "We use \n",
    "- **Mean Absolute Error (MAE)**:  \n",
    "  Interpretable as the average absolute error in pace units and distance units"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7dcde9",
   "metadata": {},
   "source": [
    "## 2.3 Relevant Baselines \n",
    "**What relevant baselines can be used for comparison?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dec7e6",
   "metadata": {},
   "source": [
    "## 2.4 Validity of Predictions\n",
    "**How you will assess the validity of your model’s predictions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70cb102",
   "metadata": {},
   "source": [
    "# 3 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff9bbf",
   "metadata": {},
   "source": [
    "## 3.1 Context \n",
    "**How do you formulate your task as an ML problem, e.g. what are the inputs, outputs, and what is being optimized? What models are appropriate for the task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960ad361",
   "metadata": {},
   "source": [
    "## 3.2 Discussion\n",
    "**Discuss the advantages and disadvantages of different modeling approaches (complexity, efficiency, challenges in implementation, etc.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059c381",
   "metadata": {},
   "source": [
    "## 3.3 Code\n",
    "**Walk through your code, explaining architectural choices and any implementation details.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2448f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert MM:SS pace to numeric \n",
    "def pace_str_to_float(p):\n",
    "    if pd.isna(p):\n",
    "        return np.nan\n",
    "    if isinstance(p, str) and \":\" in p:\n",
    "        m, s = p.split(\":\")\n",
    "        return float(m) + float(s)/60\n",
    "    return float(p)\n",
    "\n",
    "runs[\"Pace_numeric\"] = runs[\"Pace\"].apply(pace_str_to_float)\n",
    "#Sort Data by Date (Important for time trends)\n",
    "runs[\"Activity Date\"] = pd.to_datetime(runs[\"Activity Date\"])\n",
    "runs = runs.sort_values([\"Person\", \"Activity Date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5eb467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person</th>\n",
       "      <th>pace_mean_5</th>\n",
       "      <th>pace_std_5</th>\n",
       "      <th>pace_last</th>\n",
       "      <th>pace_slope_5</th>\n",
       "      <th>dist_mean_5</th>\n",
       "      <th>dist_std_5</th>\n",
       "      <th>dist_last</th>\n",
       "      <th>dist_slope_5</th>\n",
       "      <th>elev_gain_mean_5</th>\n",
       "      <th>grade_mean_5</th>\n",
       "      <th>days_since_last</th>\n",
       "      <th>next_run_pace</th>\n",
       "      <th>next_run_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>0.379510</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>-0.158333</td>\n",
       "      <td>2.036</td>\n",
       "      <td>0.329970</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.154</td>\n",
       "      <td>4.54</td>\n",
       "      <td>-1.94</td>\n",
       "      <td>3</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.050000</td>\n",
       "      <td>0.644097</td>\n",
       "      <td>6.116667</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>1.902</td>\n",
       "      <td>0.563844</td>\n",
       "      <td>1.01</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>10.52</td>\n",
       "      <td>-2.06</td>\n",
       "      <td>34</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alex</td>\n",
       "      <td>6.933333</td>\n",
       "      <td>0.474634</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>1.756</td>\n",
       "      <td>0.690167</td>\n",
       "      <td>1.03</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>10.72</td>\n",
       "      <td>-2.12</td>\n",
       "      <td>8</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.026667</td>\n",
       "      <td>0.561694</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.143333</td>\n",
       "      <td>1.600</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>1.38</td>\n",
       "      <td>-0.329</td>\n",
       "      <td>9.40</td>\n",
       "      <td>-2.44</td>\n",
       "      <td>5</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alex</td>\n",
       "      <td>7.020000</td>\n",
       "      <td>0.561545</td>\n",
       "      <td>7.016667</td>\n",
       "      <td>0.148333</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.515218</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.021</td>\n",
       "      <td>21.14</td>\n",
       "      <td>-1.90</td>\n",
       "      <td>6</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person  pace_mean_5  pace_std_5  pace_last  pace_slope_5  dist_mean_5  \\\n",
       "0   Alex     7.300000    0.379510   7.016667     -0.158333        2.036   \n",
       "1   Alex     7.050000    0.644097   6.116667     -0.375000        1.902   \n",
       "2   Alex     6.933333    0.474634   7.350000     -0.050000        1.756   \n",
       "3   Alex     7.026667    0.561694   7.600000      0.143333        1.600   \n",
       "4   Alex     7.020000    0.561545   7.016667      0.148333        1.500   \n",
       "\n",
       "   dist_std_5  dist_last  dist_slope_5  elev_gain_mean_5  grade_mean_5  \\\n",
       "0    0.329970       2.08         0.154              4.54         -1.94   \n",
       "1    0.563844       1.01        -0.158             10.52         -2.06   \n",
       "2    0.690167       1.03        -0.375             10.72         -2.12   \n",
       "3    0.663664       1.38        -0.329              9.40         -2.44   \n",
       "4    0.515218       2.00         0.021             21.14         -1.90   \n",
       "\n",
       "   days_since_last  next_run_pace  next_run_distance  \n",
       "0                3       7.350000               1.03  \n",
       "1               34       7.600000               1.38  \n",
       "2                8       7.016667               2.00  \n",
       "3                5       6.550000               2.01  \n",
       "4                6       7.600000               3.00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create rolling trend based features (using past 5 runs to predict next run)\n",
    "import numpy as np\n",
    "WINDOW = 5\n",
    "\n",
    "feature_rows = []\n",
    "\n",
    "for person, person_df in runs.groupby(\"Person\"):\n",
    "    person_df = person_df.sort_values(\"Activity Date\").reset_index(drop=True)\n",
    "\n",
    "    for i in range(WINDOW, len(person_df) - 1):\n",
    "        hist = person_df.iloc[i-WINDOW:i]\n",
    "        next_run = person_df.iloc[i+1]\n",
    "\n",
    "        row = {\n",
    "            \"Person\": person,\n",
    "\n",
    "            # ----- PACE HISTORY -----\n",
    "            \"pace_mean_5\": hist[\"Pace_numeric\"].mean(),\n",
    "            \"pace_std_5\": hist[\"Pace_numeric\"].std(),\n",
    "            \"pace_last\": hist[\"Pace_numeric\"].iloc[-1],\n",
    "            \"pace_slope_5\": np.polyfit(range(WINDOW), hist[\"Pace_numeric\"], 1)[0],\n",
    "\n",
    "            # ----- DISTANCE HISTORY -----\n",
    "            \"dist_mean_5\": hist[\"Distance\"].mean(),\n",
    "            \"dist_std_5\": hist[\"Distance\"].std(),\n",
    "            \"dist_last\": hist[\"Distance\"].iloc[-1],\n",
    "            \"dist_slope_5\": np.polyfit(range(WINDOW), hist[\"Distance\"], 1)[0],\n",
    "\n",
    "            # ----- TERRAIN HISTORY -----\n",
    "            \"elev_gain_mean_5\": hist[\"Elevation Gain\"].mean(),\n",
    "            \"grade_mean_5\": hist[\"Average Grade\"].mean(),\n",
    "\n",
    "            # ----- TIME GAP FEATURE -----\n",
    "            \"days_since_last\": (\n",
    "                person_df.iloc[i][\"Activity Date\"] -\n",
    "                person_df.iloc[i-1][\"Activity Date\"]\n",
    "            ).days,\n",
    "\n",
    "            # ----- TARGETS (NEXT RUN) -----\n",
    "            \"next_run_pace\": next_run[\"Pace_numeric\"],\n",
    "            \"next_run_distance\": next_run[\"Distance\"]\n",
    "        }\n",
    "\n",
    "        feature_rows.append(row)\n",
    "\n",
    "trend_df = pd.DataFrame(feature_rows)\n",
    "trend_df = trend_df.dropna()\n",
    "trend_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e4f0dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature matrix and targets\n",
    "X = trend_df.drop(columns=[\"next_run_pace\", \"next_run_distance\"])\n",
    "y_pace = trend_df[\"next_run_pace\"]\n",
    "y_dist = trend_df[\"next_run_distance\"]\n",
    "\n",
    "#One hot encode person and do the train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = X.drop(columns=[\"Person\"]).columns.tolist()\n",
    "categorical_features = [\"Person\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_pace_train, y_pace_test = train_test_split(\n",
    "    X, y_pace, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "_, _, y_dist_train, y_dist_test = train_test_split(\n",
    "    X, y_dist, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e97fada0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression — Pace MAE: 8.42841004549719\n",
      "Linear Regression — Pace RMSE: 19.979106193877797\n",
      "Linear Regression — Distance MAE: 1.5823890301924006\n",
      "Linear Regression — Distance RMSE: 2.324928601240988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audrey/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/audrey/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Linear regression baselines \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "linreg_pace = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_dist = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "linreg_pace.fit(X_train, y_pace_train)\n",
    "linreg_dist.fit(X_train, y_dist_train)\n",
    "\n",
    "pace_pred_lr = linreg_pace.predict(X_test)\n",
    "dist_pred_lr = linreg_dist.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression — Pace MAE:\", mean_absolute_error(y_pace_test, pace_pred_lr))\n",
    "print(\"Linear Regression — Pace RMSE:\", mean_squared_error(y_pace_test, pace_pred_lr, squared=False))\n",
    "\n",
    "print(\"Linear Regression — Distance MAE:\", mean_absolute_error(y_dist_test, dist_pred_lr))\n",
    "print(\"Linear Regression — Distance RMSE:\", mean_squared_error(y_dist_test, dist_pred_lr, squared=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79d4b17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Ridge alpha (Pace): {'model__alpha': 100}\n",
      "Ridge Pace MAE: 5.055894056823785\n",
      "Ridge Pace RMSE: 6.904936067333741\n",
      "Best Ridge alpha (Distance): {'model__alpha': 0.01}\n",
      "Ridge Distance MAE: 1.5841714721188922\n",
      "Ridge Distance RMSE: 2.3277022153770885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/audrey/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/Users/audrey/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Ridge and GridSearchCV - opimized model \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ridge_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", Ridge())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": [0.01, 0.1, 1, 10, 50, 100]\n",
    "}\n",
    "\n",
    "#ridge for pace \n",
    "ridge_grid_pace = GridSearchCV(\n",
    "    ridge_pipe, param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid_pace.fit(X_train, y_pace_train)\n",
    "\n",
    "best_ridge_pace = ridge_grid_pace.best_estimator_\n",
    "pace_pred_ridge = best_ridge_pace.predict(X_test)\n",
    "\n",
    "print(\"Best Ridge alpha (Pace):\", ridge_grid_pace.best_params_)\n",
    "print(\"Ridge Pace MAE:\", mean_absolute_error(y_pace_test, pace_pred_ridge))\n",
    "print(\"Ridge Pace RMSE:\", mean_squared_error(y_pace_test, pace_pred_ridge, squared=False))\n",
    "\n",
    "#ridge for distance \n",
    "ridge_grid_dist = GridSearchCV(\n",
    "    ridge_pipe, param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ridge_grid_dist.fit(X_train, y_dist_train)\n",
    "\n",
    "best_ridge_dist = ridge_grid_dist.best_estimator_\n",
    "dist_pred_ridge = best_ridge_dist.predict(X_test)\n",
    "\n",
    "print(\"Best Ridge alpha (Distance):\", ridge_grid_dist.best_params_)\n",
    "print(\"Ridge Distance MAE:\", mean_absolute_error(y_dist_test, dist_pred_ridge))\n",
    "print(\"Ridge Distance RMSE:\", mean_squared_error(y_dist_test, dist_pred_ridge, squared=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9dd561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last-Run Pace MAE: 1.022573839662447\n",
      "Last-Run Distance MAE: 1.8837974683544303\n"
     ]
    }
   ],
   "source": [
    "#strong baseline \n",
    "last_pace_baseline = X_test[\"pace_last\"]\n",
    "last_dist_baseline = X_test[\"dist_last\"]\n",
    "\n",
    "print(\"Last-Run Pace MAE:\", mean_absolute_error(y_pace_test, last_pace_baseline))\n",
    "print(\"Last-Run Distance MAE:\", mean_absolute_error(y_dist_test, last_dist_baseline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11451077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Pace MAE</th>\n",
       "      <th>Distance MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Run</td>\n",
       "      <td>1.022574</td>\n",
       "      <td>1.883797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>8.428410</td>\n",
       "      <td>1.582389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>5.055894</td>\n",
       "      <td>1.584171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Pace MAE  Distance MAE\n",
       "0           Last Run  1.022574      1.883797\n",
       "1  Linear Regression  8.428410      1.582389\n",
       "2   Ridge Regression  5.055894      1.584171"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Last Run\", \"Linear Regression\", \"Ridge Regression\"],\n",
    "    \"Pace MAE\": [\n",
    "        mean_absolute_error(y_pace_test, last_pace_baseline),\n",
    "        mean_absolute_error(y_pace_test, pace_pred_lr),\n",
    "        mean_absolute_error(y_pace_test, pace_pred_ridge)\n",
    "    ],\n",
    "    \"Distance MAE\": [\n",
    "        mean_absolute_error(y_dist_test, last_dist_baseline),\n",
    "        mean_absolute_error(y_dist_test, dist_pred_lr),\n",
    "        mean_absolute_error(y_dist_test, dist_pred_ridge)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1b475a",
   "metadata": {},
   "source": [
    "# 4. Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8df07",
   "metadata": {},
   "source": [
    "## 4.1 Context \n",
    "**How should your task be evaluated? Can you justify why your particular metrics are more appropriate than others?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1eb78a",
   "metadata": {},
   "source": [
    "## 4.2 Discussion \n",
    "**What are some baselines (trivial or otherwise) for your task? How do you demonstrate that your method is better than these methods?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296e6a7",
   "metadata": {},
   "source": [
    "## 4.3 Code \n",
    "**Walk through the implementation of your evaluation protocol, and support your evaluation with tables, plots, statistics, etc.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47824b61",
   "metadata": {},
   "source": [
    "# 5. Discussion of Related Work  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c382d",
   "metadata": {},
   "source": [
    "## 5.1 \n",
    "**How has this dataset been used before?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4458367",
   "metadata": {},
   "source": [
    "## 5.2 \n",
    "**How has prior work approached this same task?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2173762e",
   "metadata": {},
   "source": [
    "## 5.3 \n",
    "**How do your results match or differ from what has been reported in related work?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc80",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}